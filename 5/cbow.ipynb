{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d253d8d-b275-4fcf-b266-a98506254d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'learning': 1, 'of': 2, 'word': 3, 'words': 4, 'deep': 5, 'is': 6, 'a': 7, 'subfield': 8, 'machine': 9, 'embeddings': 10, 'capture': 11, 'semantic': 12, 'meaning': 13, 'cbow': 14, 'model': 15, 'predicts': 16, 'target': 17, 'using': 18, 'context': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (20, 50)\n",
      "Most similar to 'learning': ['words', 'is']\n",
      "Most similar to 'model': ['of', 'predicts', 'a']\n"
     ]
    }
   ],
   "source": [
    "# Assignment 5: Continuous Bag of Words (CBOW) Model\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# =====================\n",
    "# 1. Sample Text\n",
    "# =====================\n",
    "corpus = [\n",
    "    \"Deep learning is a subfield of machine learning\",\n",
    "    \"Word embeddings capture semantic meaning of words\",\n",
    "    \"CBOW model predicts target word using context words\"\n",
    "]\n",
    "\n",
    "# =====================\n",
    "# 2. Tokenization\n",
    "# =====================\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "word2id = tokenizer.word_index\n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "vocab_size = len(word2id) + 1\n",
    "\n",
    "print(\"Vocabulary:\", word2id)\n",
    "\n",
    "# Convert text to sequences\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "# =====================\n",
    "# 3. Generate CBOW Training Data\n",
    "# =====================\n",
    "window_size = 2\n",
    "X, y = [], []\n",
    "\n",
    "for seq in sequences:\n",
    "    for idx, word in enumerate(seq):\n",
    "        context = []\n",
    "        for neighbor in range(-window_size, window_size + 1):\n",
    "            if neighbor == 0:\n",
    "                continue\n",
    "            pos = idx + neighbor\n",
    "            if pos >= 0 and pos < len(seq):\n",
    "                context.append(seq[pos])\n",
    "        if len(context) > 0:\n",
    "            X.append(np.mean(context))  # simplified CBOW context\n",
    "            y.append(word)\n",
    "\n",
    "X = np.array(X).reshape(-1, 1).astype(\"int32\")\n",
    "y = to_categorical(y, vocab_size)\n",
    "\n",
    "# =====================\n",
    "# 4. Define CBOW Model\n",
    "# =====================\n",
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1),\n",
    "    Flatten(),\n",
    "    Dense(vocab_size, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "# =====================\n",
    "# 5. Train Model\n",
    "# =====================\n",
    "model.fit(X, y, epochs=100, verbose=0)\n",
    "\n",
    "# =====================\n",
    "# 6. Extract Word Embeddings\n",
    "# =====================\n",
    "weights = model.get_weights()[0]\n",
    "print(\"Embedding matrix shape:\", weights.shape)\n",
    "\n",
    "# =====================\n",
    "# 7. Test Similarity\n",
    "# =====================\n",
    "def most_similar(word, top_n=3):\n",
    "    if word not in word2id:\n",
    "        return []\n",
    "    idx = word2id[word]\n",
    "    vec = weights[idx].reshape(1, -1)\n",
    "    sims = cosine_similarity(vec, weights)[0]\n",
    "    similar_ids = sims.argsort()[-top_n-1:][::-1]\n",
    "    return [id2word[i] for i in similar_ids if i in id2word and i != idx]\n",
    "\n",
    "print(\"Most similar to 'learning':\", most_similar(\"learning\"))\n",
    "print(\"Most similar to 'model':\", most_similar(\"model\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ccf55-c623-4a22-abb1-7d7b45b3c0de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
